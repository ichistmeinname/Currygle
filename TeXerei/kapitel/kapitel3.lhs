\chapter{Analysis}\label{analysis}
This chapter looks into the requirements to build and run Curr(y)gle,
an API search engine for Curry. %
The first section deals with the creation of an index, whereas the
second and third section addresses the process of searching for a
query. %
In this context, we take a closer look of the Holumbus framework and
its features related to searching and evaluate the criteria to
accomplish a user-friendly search mechanism. %
Furthermore, we discuss the features Curr(y)gle should provide to
specify a search query. %

% Above all we need a web application to handle user queries, which is
% analyzed in the last section.

% Give a short summary about the following sections.\\

% What do we need to create this search engine? 
% The possibility to generate and update the index.\\
% The possibility to search for these informations in the index. At
% best: user-friendly \\

% What do we want above all?
% A web application for queries.

% \section{Currydoc}

\section{Creating the Index}\label{analysis:indexer}
Search engines look up information, hence, we need to collect data
that we can search for. %
This data is called index and stores all the information we want to
provide. %
In our case, we want to collect data that relates to the API of
Curry. %
Therefore, we need to think what kind of information we can provide
and decide what we want to search for. %
Secondly, we introduce the data structure provided by the Holumbus
framework that holds these information.\\ %


% The data we want to extract from a given Curry module includes at
% least the list of defined functions and data types. %
% We also want to consider the name, corresponding module and
% description of these functions and data types. %
% Additionally, general information about the module like its name and
% author needs to be stored. %

Usually, a web crawler is applied to browse the world wide web for
data. %
But since Curry is currently organized by the module documentation
generated by CurryDoc, we already have a mechanism to gain these
information about a Curry module. %
In fact, we even have more function-related information % we stated
% in the \hyperref[preliminaries:curryInfo]{previous chapter} 
because we know if a function definition is non-deterministic or
deterministic and if a given function is flexible or rigid. %
In the following, we refer to these characteristics as contexts and the
following listing presents the information or, more precisely, the
contexts that we want to provide: %

\begin{itemize}
\item name (for modules, functions and types)
\item description (for modules, function and types)
\item type signatures (for functions and types)
\item corresponding module (for functions and types)
\item author (module)
\item rigid and flexible characteristics (function)
\item non-/deterministic characteristics (function)
\end{itemize}

CurryDoc processes Curry modules and generates documentation as HTML
or \LaTeX{} output. %
For our index, we are not interested in any document markup language,
but the pure information about the Curry module. %
This observation leads to the idea of generating a new readable data
structure as an extension to CurryDoc. %
In the process we take advantage of the FlatCurry representation of a
Curry module to access these information we mentioned above. %
We discuss the actual implementation in
\hyperref[implementation:currydoc]{Section
  \ref{implementation:currydoc}}. %
In preparation of the next chapter, we introduce the data
structure |TypeExpr| that is provided by the FlatCurry module. %

\begin{code}
data TypeExpr =
     TVar TVarIndex
   | FuncType TypeExpr TypeExpr
   | TCons QName [TypeExpr] 
\end{code}


|TypeExpr| represents type expression used in function and data type
signatures. %
It consists of three constructors to distinguish between %
\begin{itemize}
\item a function type - |FuncType TypeExpr TypeExpr| 
\item a type variable  - |TVar TVarIndex| and 
\item a type constructor application - |TCons QName[TypeExpr]|
\end{itemize}

For the latter, the list of |TypeExpr| stand for the type arguments. %
Furthermore, |TVarIndex| is just a type synonym for |Int| and |QName|
represents a qualified name consisting of the module's name and the
function's or type constructor's name. %
|QName| is a type synonym for a tuple |(String,String)|. %
An unary type like |Bool| is represented as a type constructor with an
empty list, i.e. without an application to type arguments. %
The following code shows some signatures and their representation in
the |TypeExpr| data structure. %

\begin{figure}[h!]
\begin{code}
TCons (Prelude, Maybe) 
  [(TCons (Prelude, Int) []), 
  (TCons (Prelude, [ ]) [(TCons (Prelude, Char))])]
\end{code}
\caption{The representation of |Maybe Int String| as |TypeExpr|}
\end{figure}
\begin{figure}[h!]
\begin{code}
FuncType (TCons (Prelude, IO) [TVar 97]) (TCons (Prelude, IO) [TVar 97])
\end{code}
\caption{The representation of |IO a -> IO a| as |TypeExpr|}
\end{figure}
\begin{figure}[h!]
\begin{code}
FuncType (TCons (Prelude, Bool) []) 
 (FuncType (TCons (Prelude, Int) [])) (TCons (Prelude, Int) []))
\end{code}
\caption{The representation of |Bool -> Int -> Int| as |TypeExpr|}
\end{figure}

% What do we need to create an index that can be used for the Curry
% search engine?\\

% First: Curry specific information (CurryDoc)\\

% First start with the idea of the extension: instead of generating a
% document markup language, generate a readable data structure.\\

% Introduce the TypeExpr data structure that is part of the FlatCurry
% feature.\\

% Second: a data structure to hold the information (index and document
% structure from the Holumbus framework)\\

After we decide about the contents of the index, we need to discuss
the storage of these information. %
We make use of the Holumbus framework that provides data structures to
manage the collected data and interfaces to operate on these
structures. %a
The main idea is to use two structures to store the data, one for the
documents we are indexing and the other one stores the actual data we
traverse when a search is performed. %

At first, we introduce the data structures we use in our
implementation, which are provided by the framework. %
Secondly, we discuss the functionality of the interfaces. \\

In our implementation, we use |Documents a| as a data structures to
store the documents we are indexing, where |a| is the type of the
document. %
Each document of a collection has its unique identifier. %
For example, we want to construct the index for the Curry modules
|Prelude|, |IO| and |Maybe| and modules are represented
by a data structure |ModuleInfo|. %
Then these modules are the stored in |Documents ModuleInfo|. %
In order to simplify the idea, we sketch the example in pseudocode,
where the names of the modules represent values of the |ModuleInfo|
data structure. %

{\small
\begin{code}
{ (Prelude, 1), (IO, 2), (Maybe, 3) }
\end{code}}
Thus, |Documents a| can be described as a collection of documents,
where each document can be determined unambiguously.

Secondly the framework provides a structure |Inverted| for the actual
index data structure that is traversed in the search process. %
Simply put, the index stores pairs strings, where the
second entry is the word that can be searched and the first entry is
the context of this word. %
In order to provide another example, let's assume we have a Curry
module |Duck| and the following information about this module:

{\small
\begin{code}
(  "name", "Duck")
(  "author", "Donald")
(  "description",
   "If it quacks like a duck & walks like a duck, it's a duck.")
\end{code}}
% An example for our API search engine is the pair |(\textss{author},
% \textss{Donald Duck})|, with a context \emph{author},
% whose corresponding string is the author of a Curry
% module. %
As addition to the design, the identifier of the document is stored in
the index data structure to provide an association between the index
and the document the data was indexed from. %

In fact, this concept is called \emph{inverted index} or
\emph{inverted file}, which explains the name of the data type. %
Thus, in the end, the index is a collection of triples. %

{\small
\begin{code}
Documents = { (Prelude, 1), (IO, 2), (Maybe, 3), (Duck, 4)}
Inverted = 
  (  "name", "Duck", 4)
  ( "author", "Donald", 4)
  ( "description", "If it quacks [...] it's a duck.", 4)
\end{code}}

Another type provided by the framework is |HolumbusState a|: a
combination of index and documents, polymorph by the data the documents
hold. %
For the examples presented above, we would use |HolumbusState
ModuleInfo| for the index. %
In \hyperref[implementation:index]{Section \ref{implementation:index}}
we illustrate the use of these data structures in our implementation.

Holumbus provides more than these two explicit data structures to
handle the storage, it rather has multiple implementations to choose
from. %
All these implementations of the documents and index data structure
are instances of the provided interfaces. %
Therefore, we introduce the main functionalities of the interfaces we
use in our implementation. %
|HolIndex| is the name of the interface for the indexed data and the
main functionalities we are interested in, are the provided methods to
create a new triple and merge two existing structures. %
We need the same functionality for |HolDocuments|, the interface for
the document collection. %
Besides methods to merge two document collections and create a new one,
a function to change the identifier of each document in the collection
and to insert a document is provided as well.\\

To sum up, we want to extend the current CurryDoc implementation to
generate a new readable data structure about a given Curry module. %
These information cover, among other things, function and data
structure definitions, user comments and description in the source
code, and general information about the module. %
This new data structure determines the type of |HolDocuments a| and
forms one part of the index-document-duo that Holumbus provides. %

% \begin{itemize}
% \item HolDocuments - Stores the documents that correspond to the
%   index. A mapping is provided.
% \item HolIndex - Data structure to store the information, that is
%   traversed in the search process.
% \item HolumbusState a - the combination of index and document,
%   polymorph by the data the HolDocuments holds.
% \end{itemize}

\section{Searching}
% How do we search for the information in the index?
After creating the skeleton for the index and its storage, we want to
actually use these information in a search query. %
Thus, the first step is to think about the structure of a query, in the
second step we process the query and last we need a representation of
the results of the processed query for further use.\\

Fortunately, these are all features the Holumbus framework provides. At
first, we take a look at the search mechanism and the query representation. %
The data structure |Query| allows to search for a word and a phrase,
both case-insensitive and case-sensitive. %

\begin{code}
data Query = 
  Word String |
  Phrase String | 
  CaseWord String |
  CasePhrase String |
  ...
\end{code}

Since the search depends on user-input, the framework also allows
\emph{fuzzy searching} to scan for results with spelling errors like
transposed letters. %
Since the index data structure of Holumbus uses pairs of words and
contexts, a special mechanism to search for one or more contexts is
given. %
Furthermore, the structure provides binary operators to combine
multiple queries; supported operators are conjunctions, disjunctions and
negations. %

\begin{code}
data Query = 
  ... |
  FuzzySearch String |
  Specifier [Context] Query |
  BinQuery BinOp Query Query

type Context = String
data BinOp = And | Or | But
\end{code}

% And this data structure can be processed by processQuery (Holumbus.Query.Processor).
As next step, we pass the index, document and query to the function
\emph{processQuery} that, as the name suggests, processes the query. %
When processing the query, Holumbus only matches for prefixes of the
given word or phrase in a query, we need to keep this restriction in mind
when we create the index in \hyperref[implementation:index]{Section
  \ref{implementation:index}}. %


The return value of the successfully processed query is a data
structure |Result a| that consists of the matching documents with type
|a| as well as possible word completions. %

\begin{code}
-- Pseudocode with Haskell syntax
data Result a  = Result        
  { documents         :: (Document a, Score)
  , word completions  :: (String, Score)
  } 
type Score = Float
\end{code}

Additionally, each document and word completion has a calculated score between |0| and |1| that determines the
relevance of the result. %
For documents, this score is calculated by the number of occurrences of
the search query in the document by default and represented as float. %
But Holumbus also provides a mechanism to apply a customized ranking
function to calculate the score. %

If we proceed the examples of the last section, we can construct the
query

\begin{code}
Specifier ["description"] "quack"
\end{code}

and after processing, we get all modules, i.e. documents, which
description consists of the word \textss{quack} and all possible word
completions (the scores a random values to complete the example). %

\begin{code}
Result =  { documents: {("Duck", 1), 0.75} }, 
          { word completions: {"quacks", 0.8} } 
\end{code}

% The first is represented by |DocHits a| that is a mapping of |DocInfo
% a|, the contexts and the document's unique identifier. %
% On the other hand |DocInfo a| consists of the matching document and a
% score. %

% \begin{code} 
% data DocInfo a = DocInfo 
%   { document :: (Document a)
%   , docScore  :: Score
%  }
% type DocContextHits    = Map Context DocWordHits

% type DocWordHits       = Map Word Positions

% type DocHits a  = DocIdMap (DocInfo a, DocContextHits)
% \end{code}

% By default this score is calculated by the number of occurrences of
% the search query in the document and represented as |Float|. %
% But Holumbus also provides a mechanism to apply a customized ranking
% function to calculate the score. %
% |WordHits| illustrates the word completions and is represented by a
% mapping of the possible completions of the given prefix in combination
% with its score, i.e. |WordInfo|, and the contexts.\\
% Holumbus also provides a data structure that is returned after a query

% \begin{code}
% data WordInfo  = WordInfo 
%                 { terms     :: Terms
%                 , wordScore :: Score                
%                 }

% type WordHits          = Map Word (WordInfo, WordContextHits)

% type WordContextHits   = Map Context WordDocHits

% type WordDocHits       = Occurrences
% \end{code}


Summing up, we have discussed the mechanism to evaluate a query with
the Holumbus framework. %
The provided mechanism includes the data structures to represent a
query, which can be processed to a data structure consisting of the
matching documents and possible word completions. %
% But first the user input has to be parsed into the query structure to
% start the processing.

\section{Parsing User-Queries}\label{analysis:parser}
% Which criteria do we want to search for? Modules, functions, types,
% signatures, and  det./non-det., flexible/rigid functions. \\
The next question is how to construct the query for a given
user-input. %
At first we have to decide about the criteria users can search for. %
Since the index provides the pairs of contexts and search words, we
are able to restrict the search to all these contexts with the help of
the |Query| data structure and the |Specifier| constructor. %
This structure of the index allows us to search for modules,
functions, types, signatures and all other contexts we use during the
creation of the index.\\

% First describe the idea, that the use of a specific language increases
% the usability. But it also restricts the user in her usage of the
% search engine, if this language gets more complex. So this results in
% a compromise between a simply to use language and a language that can
% be parsed.  Show the example of searching IO, where the restriction to
% modules minimizes the result.\\
The search mechanism as part of the user-experience is supposed to be
as simple as possible. %
The right use of a specific language can increase the usability. %
A good example is the search term |"io"|, since in Curry \emph{IO}
is the name for a module, a type and a constructor. %
Furthermore, there are many functions in the IO module that contain
the word \emph{io}. Thus, the search for \emph{io} results in a great
amount of hits. %
We can restrict the search to a specific context to reduce the number
of hits. %
Therefore, we want to provide specifiers the user combines with the
search term, for example |":function IO"| searches for \emph{IO} in
the context of function names only. %
But this special syntax restricts the user in the use of the search
engine, if the language gets more complex. %
Thus, in order to provide a user-friendly search engine, we have to make a
compromise between a simple language and a language that can be
parsed. %

% Set the focus on signatures. Because Hayoo! does not find signatures with
% redundant parentheses, Curr(y)gle supports parenthesized signatures
% and parenthesized query parts in general. \\
Besides these specifiers we want to parse type signatures of Curry
functions and data types. %
During our test phase, we also studied Hayoo!, the first search engine
that was build with the Holumbus Framework. %
We recognized that Hayoo! is not able to parse redundant parenthesized
signatures.  In our opinion, this parsing behavior can be irritating
in the usage of the search engine, therefore, we want to address the
problem of redundant parentheses with great care when we parse
signatures. %
For instance, let's assume a beginner searches for a function with the
type signature |"IO -> (IO Int)"|. %
The type \emph{IO Int} and type constructors in general do not need
parentheses, but as beginner you might think they do. %
Thus, we want to support parenthesized signatures and parenthesized
query parts in general. %

Last but not least we want to provide binary conjunctions like
\emph{And}, \emph{Or} and \emph{Not}. %
On the one hand, a combination of more search words is desirable
because popular search engines like Google\texttrademark~ support
binary operations as feature. %
The popularity increases the probability that users assume binary
operations are standard features and expect search engines to provide
the conjunction of several search terms. %
On the other hand, if the desired result is still vague, a combination
of more search words by a disjunction \emph{Or} helps to narrow down
the search results.\\
% In addition: binary operations/conjunctions. \\
% Explain that in most cases, a combination of more search words is
% desirable, because first popular search engines like Google\texttrademark~use this
% feature so it's common knowledge (the user expects this features) and
% second it's easier to search for more search words, if the desired
% result is still vague.

In the end, we want to provide an intuitive but powerful syntax for
the search engine. %
With specifiers to restrict the search results to a given context and
with binary operations to narrow down or extend the contexts, we want
to provide a simple language for the user queries. %
Additionally, type signatures should be recognized, including
function, construction and primitive types as well as redundant
parenthesized signatures. %
As the number of the supported features increases, the query gets more
complex to read. %
Thus, to reach this goal, we need to analyse the user input and
rebuild it as an expression of our |Query| data structure. %
The following figures describe the language the parser supports and in
\hyperref[implementation:parser]{Section \ref{implementation:parser}}
we discuss our actual implementation. % 

